{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5722d86",
   "metadata": {},
   "source": [
    "# 14 â€” Using a Vector Store as a Retriever\n",
    "\n",
    "A **retriever** is a unified interface that, given a query, returns the **most relevant Documents** from an index â€” usually a **vector store** like Chroma.\n",
    "\n",
    "Instead of calling `similarity_search()` manually, we can convert a vector store into a retriever with `.as_retriever()` and use it as part of a RAG (Retrieval-Augmented Generation) pipeline.\n",
    "\n",
    "âœ… **Advantage:** you can easily change search strategy (similarity, MMR, threshold, filters) without rewriting logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcaf3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment loaded.\n"
     ]
    }
   ],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘ Setup: Load environment variables & initialize model â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "print(\"âœ… Environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3cade",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Build or reuse a vector store\n",
    "\n",
    "We'll reuse the logic from the previous notebook (embedding and storing documents in Chroma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20637b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store ready with 1 document.\n"
     ]
    }
   ],
   "source": [
    "# Dummy document fallback (if not loaded before)\n",
    "from langchain_core.documents import Document\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"Solar energy is one of the most promising renewable energy sources today. \"\n",
    "        \"It converts sunlight directly into electricity using photovoltaic cells. \"\n",
    "        \"Wind energy uses turbines to transform air currents into mechanical power. \"\n",
    "        \"Governments are investing heavily in renewables to reach carbon neutrality by 2050. \"\n",
    "        \"Research also focuses on improving energy storage systems such as lithium-ion batteries.\"\n",
    "    ), metadata={\"source\": \"renewable_energy.txt\"})\n",
    "]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "print(\"Vector store ready with 1 document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc6ade",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Create a retriever\n",
    "\n",
    "The retriever wraps the vector store and standardizes access to relevant documents. \n",
    "By default, it uses **similarity search** and returns 4 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44bde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 2 documents.\n",
      "Solar energy is one of the most promising renewable energy sources today. It converts sunlight directly into electricity using photovoltaic cells. Wind energy uses turbines to transform air currents into mechanical power. Governments are investing heavily in renewables to reach carbon neutrality by 2050. Research also focuses on improving energy storage systems such as lithium-ion batteries.\n",
      "{'source': 'renewable_energy.txt'}\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",   # 'similarity' | 'mmr' | 'similarity_score_threshold'\n",
    "    search_kwargs={\"k\": 4}      # number of documents to return\n",
    ")\n",
    "\n",
    "query = \"What technologies are used to generate renewable energy?\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Retrieved {len(docs)} documents.\")\n",
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106db59",
   "metadata": {},
   "source": [
    "Each element in the response is a **Document** with:\n",
    "- `page_content` â†’ the text chunk.\n",
    "- `metadata` â†’ info such as file path, page, section, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8b68e",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Adjusting retrieval strategy\n",
    "\n",
    "### a) Return more (or fewer) chunks\n",
    "```python\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "```\n",
    "\n",
    "### b) Use MMR (Maximal Marginal Relevance)\n",
    "This strategy increases **diversity** by avoiding redundant results.\n",
    "```python\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 6, \"fetch_k\": 20}\n",
    ")\n",
    "```\n",
    "\n",
    "### c) Use similarity with a minimum score threshold\n",
    "Discard results that are not close enough.\n",
    "```python\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.2, \"k\": 8}\n",
    ")\n",
    "```\n",
    "\n",
    "### d) Filter by metadata (when supported)\n",
    "```python\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 4,\n",
    "        \"filter\": {\"source\": \"renewable_energy.txt\"}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94ed0e",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Typical retriever output\n",
    "\n",
    "```python\n",
    "len(response)   # â†’ 4\n",
    "response[0]     # â†’ Document(...)\n",
    "response        # â†’ [Document(...), Document(...), Document(...), Document(...)]\n",
    "```\n",
    "\n",
    "Example of one Document:\n",
    "```python\n",
    "Document(\n",
    "  page_content=\"Solar energy is one of the most promising renewable energy sources today...\",\n",
    "  metadata={'source': './data/renewable_energy.txt'}\n",
    ")\n",
    "```\n",
    "\n",
    "The retriever found the relevant text **by meaning**, not by exact words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d223a5",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Why use retrievers instead of calling `.similarity_search()` directly?\n",
    "\n",
    "- The retriever gives you a **standard interface** that LangChain chains and tools expect.\n",
    "- You can **swap strategies** (similarity, MMR, threshold) easily.\n",
    "- It integrates natively with RAG chains, evaluators, and agents.\n",
    "\n",
    "In short â†’ `retriever = vectorstore.as_retriever()` is a lightweight adapter layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913831e",
   "metadata": {},
   "source": [
    "## ğŸ”§ Best practices\n",
    "\n",
    "- **Chunk size:** 700â€“1200 chars with ~200 overlap works well for long docs.\n",
    "- **Metadata:** always store `source`, `page`, or `section` â†’ useful for citations.\n",
    "- **Inspect results:** check a few `.page_content` outputs to validate relevance.\n",
    "- **MMR:** improves recall diversity (less redundancy).\n",
    "- **Thresholds:** tune `score_threshold` to filter low-confidence matches.\n",
    "- **Compression (advanced):** use a *context compressor* to shorten retrieved chunks before sending them to the LLM (useful when token limits are tight)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050ac44",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "- A **retriever** wraps your vector store to return relevant Documents for a query.\n",
    "- Itâ€™s flexible, composable, and plug-and-play for RAG chains.\n",
    "- You can change retrieval logic (similarity, MMR, thresholds) without touching LLM code.\n",
    "- The result is a list of Documents with text + metadata â†’ ready to feed into a prompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
