{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3046401a",
   "metadata": {},
   "source": [
    "# 07 ‚Äî Types of Chains (Core Runnables)\n",
    "\n",
    "In LangChain LCEL (LangChain Expression Language), **chains** are built by connecting *runnables* ‚Äî small modular units that process data.\n",
    "\n",
    "In this notebook, you‚Äôll learn three fundamental types of runnables:\n",
    "\n",
    "1. `RunnablePassthrough` ‚Äî passes input unchanged.\n",
    "2. `RunnableLambda` ‚Äî wraps any custom Python function.\n",
    "3. `RunnableParallel` ‚Äî runs several branches in parallel and merges results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96617d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded and model ready.\n"
     ]
    }
   ],
   "source": [
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë Setup: Load environment variables & initialize model ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# chat_model = ChatGroq(model=\"llama-3.1-70b-versatile\")\n",
    "\n",
    "print(\"‚úÖ Environment loaded and model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab722551",
   "metadata": {},
   "source": [
    "# **1Ô∏è‚É£ RunnablePassthrough (LCEL)**\n",
    "\n",
    "### What is it?\n",
    "`RunnablePassthrough` returns exactly the same input it receives ‚Äî without modification.\n",
    "It‚Äôs useful when you want to **propagate the original input** along with other operations in a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc046fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abram\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()\n",
    "print(chain.invoke(\"Abram\"))  # ‚Üí \"Abram\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e224299",
   "metadata": {},
   "source": [
    "### üß† Practical uses\n",
    "\n",
    "**1. Parallel branches (fan-out)**\n",
    "\n",
    "When you want to construct a dictionary with multiple outputs, and one of them is the unmodified input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fd3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "pipeline = {\n",
    "    \"original\": RunnablePassthrough(),\n",
    "    \"upper\": lambda x: x.upper(),\n",
    "    \"len\": lambda x: len(x),\n",
    "}\n",
    "print(pipeline[\"len\"](\"Abram\"))  # ‚Üí 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e34c6b",
   "metadata": {},
   "source": [
    "**2. Combine context + input**\n",
    "\n",
    "Keep the raw query while adding metadata:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich = {\n",
    "    \"query\": RunnablePassthrough(),\n",
    "    \"metadata\": lambda q: {\"chars\": len(q), \"has_space\": \" \" in q},\n",
    "}\n",
    "print(enrich[\"metadata\"](\"LangChain rocks!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80dcfb",
   "metadata": {},
   "source": [
    "‚úÖ **When to use**\n",
    "- When you need to pass input untouched to the next stage.\n",
    "- When building dict outputs with original + transformed versions.\n",
    "- As a connector node to retain the original input.\n",
    "\n",
    "‚ö†Ô∏è **Gotcha:** it passes references, not deep copies ‚Äî if you mutate objects later, make your own copy first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097722c",
   "metadata": {},
   "source": [
    "# **2Ô∏è‚É£ RunnableLambda (LCEL)**\n",
    "\n",
    "### What is it?\n",
    "`RunnableLambda` wraps any Python function and turns it into a runnable that can be composed inside a chain.\n",
    "It‚Äôs the wildcard tool for custom logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa60bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abramovich\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\"\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)\n",
    "print(chain.invoke(\"Abram\"))  # ‚Üí \"Abramovich\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c42913",
   "metadata": {},
   "source": [
    "### üß† Practical uses\n",
    "\n",
    "1. **Inject custom logic**\n",
    "```python\n",
    "RunnableLambda(lambda x: x[::-1])  # reverses strings\n",
    "```\n",
    "\n",
    "2. **Preprocess data before LLM**\n",
    "```python\n",
    "def normalize(text: str) -> str:\n",
    "    return text.lower().strip()\n",
    "chain = RunnableLambda(normalize)\n",
    "```\n",
    "\n",
    "3. **Postprocess model results**\n",
    "```python\n",
    "clean_chain = chat_model | RunnableLambda(lambda x: x.replace(\"\\n\", \" \"))\n",
    "```\n",
    "\n",
    "4. **Integrate external libraries**\n",
    "```python\n",
    "import math\n",
    "chain = RunnableLambda(lambda x: math.sqrt(x))\n",
    "print(chain.invoke(9))  # ‚Üí 3.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322a320",
   "metadata": {},
   "source": [
    "‚úÖ **When to use**\n",
    "- For lightweight custom transformations.\n",
    "- When a dedicated runnable doesn‚Äôt exist.\n",
    "- When adding Python logic inline inside a chain.\n",
    "\n",
    "‚ö†Ô∏è **Gotchas**\n",
    "- Functions should be pure (no global side effects).\n",
    "- Async functions are supported.\n",
    "- Use `functools.partial` if you need fixed arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b406ded",
   "metadata": {},
   "source": [
    "# **3Ô∏è‚É£ RunnableParallel (LCEL)**\n",
    "\n",
    "### What is it?\n",
    "`RunnableParallel` executes several sub-tasks in parallel and merges the results into a single dictionary.\n",
    "\n",
    "In LCEL, when you pass a **dict** in a chain, it automatically acts as a `RunnableParallel` ‚Äî you don‚Äôt always need to instantiate it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c719ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'LangChain', 'upper': 'LANGCHAIN', 'chars': 9}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def to_upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "def count_chars(text: str) -> int:\n",
    "    return len(text)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"original\": RunnablePassthrough(),\n",
    "    \"upper\": RunnableLambda(to_upper),\n",
    "    \"chars\": RunnableLambda(count_chars),\n",
    "})\n",
    "\n",
    "print(parallel_chain.invoke(\"LangChain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb213626",
   "metadata": {},
   "source": [
    "### üß© Explanation\n",
    "\n",
    "Each branch runs independently and receives the same input.\n",
    "When all finish, the results are merged into a dictionary.\n",
    "\n",
    "üëâ Output example:\n",
    "\n",
    "```python\n",
    "{'original': 'LangChain', 'upper': 'LANGCHAIN', 'chars': 9}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facbf45",
   "metadata": {},
   "source": [
    "### üß† What is `itemgetter`?\n",
    "\n",
    "`itemgetter` (from Python‚Äôs `operator` module) lets you extract a specific key from a dictionary.\n",
    "It‚Äôs often used inside parallel or composed chains when you want to **propagate only part of the input**.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "from operator import itemgetter\n",
    "\n",
    "extract_name = itemgetter('name')\n",
    "print(extract_name({'name': 'Marie', 'age': 35}))  # ‚Üí 'Marie'\n",
    "```\n",
    "\n",
    "This is useful when you want to route only a certain field into a chain stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1251cb",
   "metadata": {},
   "source": [
    "### **Important: the syntax of RunnableParallel can have several variations**\n",
    "\n",
    "When composing a `RunnableParallel` with another runnable, you don‚Äôt need to explicitly wrap it inside the class.\n",
    "\n",
    "Inside a chain, the following three syntaxes are **equivalent**:\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# 1Ô∏è‚É£ Explicit instantiation\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "\n",
    "# 2Ô∏è‚É£ Keyword-style instantiation\n",
    "RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "\n",
    "# 3Ô∏è‚É£ Dictionary shorthand (most common in LCEL)\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "```\n",
    "\n",
    "In LCEL, passing a dictionary directly is the most typical way to express parallel branches ‚Äî it‚Äôs automatically interpreted as a `RunnableParallel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ee94a",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "| Runnable Type | Purpose | Typical Use |\n",
    "|----------------|----------|-------------|\n",
    "| **RunnablePassthrough** | Pass input unchanged | Keep or reuse raw data |\n",
    "| **RunnableLambda** | Wrap custom Python logic | Transformations, preprocessing, postprocessing |\n",
    "| **RunnableParallel** | Run multiple branches at once | Build dicts, prepare multiple variables, fan-out inputs |\n",
    "\n",
    "These three are the **foundation of modern LCEL chains**, allowing you to build modular, parallel, and composable workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
