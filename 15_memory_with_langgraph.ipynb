{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5c37e1",
   "metadata": {},
   "source": [
    "# 15 — Memory with LangGraph (Short-term & Persistent)\n",
    "\n",
    "This notebook shows how to add **chat memory** using **LangGraph** checkpointers (recommended in LangChain v0.3+). We cover:\n",
    "\n",
    "1) **Short-term memory** with `MemorySaver` (in RAM).\n",
    "2) **Persistent memory** with `SqliteSaver` (on disk).\n",
    "\n",
    "We use `MessagesState` + `StateGraph` + a `thread_id` to scope history per conversation. See the official guide for message history and LangGraph persistence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61778cc",
   "metadata": {},
   "source": [
    "> Docs:\n",
    "> - How to add message history (LangChain v0.3+):\n",
    ">   - https://python.langchain.com/docs/how_to/message_history/\n",
    "> - LangGraph checkpointing (Memory/SQLite/Postgres):\n",
    ">   - https://langchain-ai.github.io/langgraph/reference/checkpoints/\n",
    "> - Persistence overview & sqlite package note:\n",
    ">   - https://langchain-ai.github.io/langgraph/concepts/persistence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eb202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment loaded and model ready.\n"
     ]
    }
   ],
   "source": [
    "# ╔══════════════════════════════════════════════════════╗\n",
    "# ║ Setup: env & model                                  ║\n",
    "# ╚══════════════════════════════════════════════════════╝\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = ChatGroq(model=\"llama-3.1-70b-versatile\")\n",
    "\n",
    "print(\"✅ Environment loaded and model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e65753",
   "metadata": {},
   "source": [
    "## 1) Short-term memory with `MemorySaver`\n",
    "\n",
    "We define a **single-node** graph that sends the current message history to the model and appends the AI reply back into state.\n",
    "\n",
    "We compile with **`MemorySaver`** (in-memory checkpointer). History is scoped by `thread_id` in `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c253520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Alex! How can I assist you today?\n",
      "Your name is Alex. How can I help you today, Alex?\n",
      "I don’t have the ability to remember past interactions, but I'm here to help you with any questions or topics you want to discuss! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Define a chat workflow over MessagesState (list of messages)\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    # state['messages'] is a list[BaseMessage]; we pass it directly to the model\n",
    "    ai_msg = llm.invoke(state[\"messages\"])  # returns an AIMessage\n",
    "    return {\"messages\": ai_msg}\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# In-memory memory (short-term)\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Each distinct thread gets its own conversation history\n",
    "cfg = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "# Turn 1\n",
    "out = app.invoke({\"messages\": [HumanMessage(\"Hi! My name is Alex.\")]}, cfg)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "# Turn 2 (same thread → history is preserved)\n",
    "out = app.invoke({\"messages\": [HumanMessage(\"What is my name?\")]}, cfg)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "# New thread (no prior history)\n",
    "cfg2 = {\"configurable\": {\"thread_id\": \"demo-thread-2\"}}\n",
    "out2 = app.invoke({\"messages\": [HumanMessage(\"Do you remember me?\")]}, cfg2)\n",
    "print(out2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5c214",
   "metadata": {},
   "source": [
    "**What happened?**\n",
    "- The app persists message history **per `thread_id`** using LangGraph checkpoints.\n",
    "- Re-invocations on the same thread include prior messages in `MessagesState` automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4aa02",
   "metadata": {},
   "source": [
    "## 2) Persistent memory with `SqliteSaver`\n",
    "\n",
    "To persist across kernel restarts, use **SQLite**. Install the separate package:\n",
    "\n",
    "```bash\n",
    "pip install -U langgraph-checkpoint-sqlite\n",
    "```\n",
    "\n",
    "Then compile the same graph with `SqliteSaver`. (You can also use Postgres via `langgraph-checkpoint-postgres`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0520d388",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_GeneratorContextManager' object has no attribute 'get_next_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m app_sqlite = workflow.compile(checkpointer=sqlite_memory)\n\u001b[32m      7\u001b[39m cfg_sql = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcustomer-42\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m out = \u001b[43mapp_sqlite\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi, I\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mm Jamie. Please remember it.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_sql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(out[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# On a later run (even after restarting the kernel), the thread history is loaded from SQLite:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/02-langchain-beginners/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/02-langchain-beginners/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2615\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2612\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2613\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2615\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2616\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[32m   2636\u001b[39m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[32m   2637\u001b[39m     runner = PregelRunner(\n\u001b[32m   2638\u001b[39m         submit=config[CONF].get(\n\u001b[32m   2639\u001b[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001b[32m   (...)\u001b[39m\u001b[32m   2642\u001b[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001b[32m   2643\u001b[39m     )\n\u001b[32m   2644\u001b[39m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/02-langchain-beginners/.venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:974\u001b[39m, in \u001b[36mSyncPregelLoop.__init__\u001b[39m\u001b[34m(self, input, stream, config, store, cache, checkpointer, nodes, specs, trigger_to_nodes, durability, manager, interrupt_after, interrupt_before, input_keys, output_keys, stream_keys, migrate_checkpoint, retry_policy, cache_policy)\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;28mself\u001b[39m.stack = ExitStack()\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_get_next_version = \u001b[43mcheckpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next_version\u001b[49m\n\u001b[32m    975\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes = checkpointer.put_writes\n\u001b[32m    976\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes_accepts_task_path = (\n\u001b[32m    977\u001b[39m         signature(checkpointer.put_writes).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mtask_path\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    978\u001b[39m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    979\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: '_GeneratorContextManager' object has no attribute 'get_next_version'"
     ]
    }
   ],
   "source": [
    "# If not installed, run: pip install -U langgraph-checkpoint-sqlite\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "sqlite_memory = SqliteSaver.from_conn_string(\"chat_memory.db\")  # persisted on disk\n",
    "app_sqlite = workflow.compile(checkpointer=sqlite_memory)\n",
    "\n",
    "cfg_sql = {\"configurable\": {\"thread_id\": \"customer-42\"}}\n",
    "out = app_sqlite.invoke({\"messages\": [HumanMessage(\"Hi, I'm Jamie. Please remember it.\")]}, cfg_sql)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "# On a later run (even after restarting the kernel), the thread history is loaded from SQLite:\n",
    "out = app_sqlite.invoke({\"messages\": [HumanMessage(\"What is my name?\")]}, cfg_sql)\n",
    "print(out[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402bb36",
   "metadata": {},
   "source": [
    "> **Tip:** You can inspect or mutate state:\n",
    "```python\n",
    "state_view = app_sqlite.get_state(cfg_sql).values\n",
    "for m in state_view[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "```\n",
    "You can also **truncate/trim** messages if the history grows too large (custom policy). See the message-history guide for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e85a5b",
   "metadata": {},
   "source": [
    "## 3) Multi-input state (prompt params + messages)\n",
    "\n",
    "When your runnable accepts multiple inputs (e.g., a `language` parameter plus `messages`), define a **TypedDict** state and mark the messages channel with `add_messages` so new messages **append**, while scalar fields **overwrite**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e78498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer in {language}. Be concise.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "runnable = prompt | llm\n",
    "\n",
    "wf2 = StateGraph(state_schema=ChatState)\n",
    "def call_model_dict(state: ChatState):\n",
    "    # Pass the whole dict (messages + language) to the runnable\n",
    "    ai_msg = runnable.invoke(state)\n",
    "    return {\"messages\": [ai_msg]}  # append the new AI message\n",
    "\n",
    "wf2.add_node(\"model\", call_model_dict)\n",
    "wf2.add_edge(START, \"model\")\n",
    "\n",
    "app2 = wf2.compile(checkpointer=MemorySaver())\n",
    "cfg = {\"configurable\": {\"thread_id\": \"lang-es-1\"}}\n",
    "out = app2.invoke({\"messages\": [HumanMessage(\"Hi, I'm Bob.\")], \"language\": \"Spanish\"}, cfg)\n",
    "print(out[\"messages\"][-1].content)  # Expect Spanish reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95164642",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "- Use **`thread_id`** to isolate conversations by user/session.\n",
    "- **Short-term (MemorySaver)** for demos/tests; **SQLite/Postgres** for apps that must survive restarts.\n",
    "- Limit history (e.g., last *k* messages) or **summarize** when token budgets are tight.\n",
    "- Store useful metadata in your DB if you’ll analyze or filter threads later.\n",
    "- For agents/tools/multi-step workflows, LangGraph checkpointing also enables **human-in-the-loop**, **time-travel/replay**, and **fault recovery**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
