{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9b6c17",
   "metadata": {},
   "source": [
    "# 11 — Text Splitters (RecursiveCharacterTextSplitter)\n",
    "\n",
    "A **text splitter** breaks a large document into smaller, manageable **chunks**. This is essential for LLMs, which have **context window limits**.\n",
    "\n",
    "By splitting text you can:\n",
    "- Search and retrieve more precisely.\n",
    "- Process data efficiently.\n",
    "- Feed the model coherent fragments instead of arbitrary cuts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════╗\n",
    "# ║ Setup: Load environment variables & initialize model ║\n",
    "# ╚══════════════════════════════════════════════════════╝\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# chat_model = ChatGroq(model=\"llama-3.1-70b-versatile\")\n",
    "\n",
    "print(\"✅ Environment loaded and model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c3f4e",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "\n",
    "**RecursiveCharacterTextSplitter** tries a list of separators **from largest to smallest**. If a chunk is still too long after trying a given separator, it recursively tries the next one.\n",
    "\n",
    "Typical separators order:\n",
    "1. Paragraphs (e.g., `\"\\n\\n\"`)\n",
    "2. New lines (e.g., `\"\\n\"`)\n",
    "3. Sentences (regex like `\"(?<=\\. )\"`)\n",
    "4. Words (`\" \"`)\n",
    "5. Characters (`\"\"`)\n",
    "\n",
    "Key parameters:\n",
    "- `chunk_size` → maximum size of each chunk (here **characters**, not tokens).\n",
    "- `chunk_overlap` → how much two consecutive chunks overlap.\n",
    "- `separators` → ordered list the splitter will try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b88479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "second_recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(second_recursive_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f8f52",
   "metadata": {},
   "source": [
    "### Separators in detail\n",
    "- `\"\\n\\n\"` — **double newline** → paragraph boundaries.\n",
    "- `\"\\n\"` — **single newline** → new lines within lists/blocks.\n",
    "- `\"(?<=\\. )\"` — **regex lookbehind** that splits **after a period and a space** (sentence boundaries).\n",
    "- `\" \"` — **space** → words.\n",
    "- `\"\"` — **empty string** → characters (last resort)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2c86f",
   "metadata": {},
   "source": [
    "## Practical example\n",
    "We will split the following text using the splitter configured above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ab558",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = (\n",
    "    \"Data that Speak\\n\"\n",
    "    \"LLM Applications are revolutionizing industries such as \\n\"\n",
    "    \"banking, healthcare, insurance, education, legal, tourism,\\n\"\n",
    "    \"construction, logistics, marketing, sales, customer service, \\n\"\n",
    "    \"and even public administration.\\n\\n\"\n",
    "    \"The aim of our programs is for students to learn how to \\n\"\n",
    "    \"create LLM Applications in the context of a business,\\n\"\n",
    "    \"which presents a set of challenges that are important \\n\"\n",
    "    \"to consider in advance.\"\n",
    ")\n",
    "\n",
    "chunks = second_recursive_splitter.split_text(text2)\n",
    "for i, ch in enumerate(chunks, 1):\n",
    "    print(f\"[{i}] len={len(ch)}\\n{ch}\\n---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6f904",
   "metadata": {},
   "source": [
    "You should see coherent chunks, first attempting paragraphs, then sentences, then smaller units as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8125346",
   "metadata": {},
   "source": [
    "## Tips: choosing `chunk_size` and `chunk_overlap`\n",
    "\n",
    "- Start with **small chunks** (e.g., 200–400 characters) for demos, then adjust.\n",
    "- Use a small **overlap** (e.g., 10–50 characters) when you need to preserve context between adjacent chunks (headings/sentences that span boundaries).\n",
    "- Remember this splitter works with **characters**. For token-aware splitting, prefer `TokenTextSplitter` or set chunk sizes based on tokenization utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff958ff",
   "metadata": {},
   "source": [
    "## Why this matters for RAG\n",
    "\n",
    "In RAG pipelines, you typically:\n",
    "1. **Load** documents (Data Loaders).\n",
    "2. **Split** them into coherent chunks (this step).\n",
    "3. **Embed** and **index** those chunks in a vector store.\n",
    "4. **Retrieve** the most relevant chunks for a query and feed them to the LLM.\n",
    "\n",
    "Good splitting preserves semantic coherence and improves retrieval quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
